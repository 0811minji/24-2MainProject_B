{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb582c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-comment-downloader in c:\\users\\diane\\anaconda3\\lib\\site-packages (0.1.76)\n",
      "Requirement already satisfied: requests in c:\\users\\diane\\anaconda3\\lib\\site-packages (from youtube-comment-downloader) (2.27.1)\n",
      "Requirement already satisfied: dateparser in c:\\users\\diane\\anaconda3\\lib\\site-packages (from youtube-comment-downloader) (1.2.0)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\diane\\anaconda3\\lib\\site-packages (from dateparser->youtube-comment-downloader) (5.2)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in c:\\users\\diane\\anaconda3\\lib\\site-packages (from dateparser->youtube-comment-downloader) (2022.3.15)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\diane\\anaconda3\\lib\\site-packages (from dateparser->youtube-comment-downloader) (2.8.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\diane\\anaconda3\\lib\\site-packages (from dateparser->youtube-comment-downloader) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diane\\anaconda3\\lib\\site-packages (from python-dateutil->dateparser->youtube-comment-downloader) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diane\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\diane\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\diane\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diane\\anaconda3\\lib\\site-packages (from requests->youtube-comment-downloader) (2021.10.8)\n",
      "Requirement already satisfied: tzdata in c:\\users\\diane\\anaconda3\\lib\\site-packages (from tzlocal->dateparser->youtube-comment-downloader) (2024.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-comment-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f822043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212a585",
   "metadata": {},
   "source": [
    "# Scroll down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ChromeDriver 설정\n",
    "#options = Options()\n",
    "##options.add_argument('--headless')  # GUI 없이 실행\n",
    "#options.add_argument('--no-sandbox')\n",
    "#options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "## WebDriver 생성\n",
    "#driver = webdriver.Chrome(options=options)\n",
    "\n",
    "## 유튜브 댓글 크롤링 함수\n",
    "#def crawl_youtube_comments(driver, 방송, 식당):\n",
    "#    search_query = f\"{식당} {방송}\"\n",
    "#    driver.get(f\"https://www.youtube.com/results?search_query={search_query}\")\n",
    "#    time.sleep(3)  # Wait for the search results page to load\n",
    "\n",
    "#    # Collect video URLs\n",
    "#    videos = driver.find_elements(By.CSS_SELECTOR, '#dismissible > ytd-thumbnail')[:5]\n",
    "#    urls = []\n",
    "#    for video in videos:\n",
    "#        try:\n",
    "#            video_url = video.find_element(By.CSS_SELECTOR, 'a').get_attribute('href')\n",
    "#            if video_url:\n",
    "#                urls.append(video_url)\n",
    "#                print(f\"수집된 URL: {video_url}\")  # 디버깅용 출력\n",
    "#        except Exception as e:\n",
    "#            print(f\"URL 수집 실패: {e}\")\n",
    "\n",
    "#    results = []\n",
    "#    for index, url in enumerate(urls):\n",
    "#        try:\n",
    "#            driver.get(url)\n",
    "#            # Wait for the page title to load\n",
    "#            WebDriverWait(driver, 20).until(\n",
    "#                EC.presence_of_element_located((By.CSS_SELECTOR, '#title > h1 > yt-formatted-string'))\n",
    "#            )\n",
    "#            video_title = driver.find_element(By.CSS_SELECTOR, '#title > h1 > yt-formatted-string').text\n",
    "#            print(f\"[{index + 1}] Title: {video_title}\")\n",
    "\n",
    "#            # Scroll to load comments\n",
    "#            scroll_pause_time = 5\n",
    "#            last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "#            while True:\n",
    "#                driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "#                time.sleep(scroll_pause_time)\n",
    "#                new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "#                if new_height == last_height:  # No more scrolling possible\n",
    "#                    break\n",
    "#                last_height = new_height\n",
    "\n",
    "#            # Collect comments and users\n",
    "#            try:\n",
    "#                comment_box = driver.find_element(By.CSS_SELECTOR, '#sections')\n",
    "#                comments = comment_box.find_elements(By.CSS_SELECTOR, '#content-text')\n",
    "#                users = comment_box.find_elements(By.CSS_SELECTOR, 'a#author-text')\n",
    "                \n",
    "#                for comment, user in zip(comments, users):\n",
    "#                    results.append({\n",
    "#                        \"식당명\": f\"{식당}\",\n",
    "#                        \"방송\": f\"{방송}\",\n",
    "#                        \"Title\": video_title,\n",
    "#                        \"User\": user.text.strip(),\n",
    "#                        \"Comment\": comment.text.strip(),\n",
    "#                    })\n",
    "                \n",
    "#            except Exception as e:\n",
    "#                print(f\"댓글 수집 실패: {e}\")\n",
    "            \n",
    "#        except Exception as e:\n",
    "#            print(f\"Error processing video at {url}: {e}\")\n",
    "#            continue  # Skip to the next video\n",
    "\n",
    "#    # Save results\n",
    "#    if results:\n",
    "#        try:\n",
    "#            df = pd.DataFrame(results)\n",
    "#            output_file = f\"youtubecomments_{식당}.csv\"\n",
    "#            df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "#            print(f\"Saved comments to {output_file}\")\n",
    "#        except Exception as e:\n",
    "#            print(f\"Failed to save comments for {식당}: {e}\")\n",
    "#    else:\n",
    "#        print(f\"No comments collected for {식당}.\")\n",
    "\n",
    "##식당 정보 불러오기\n",
    "#restaurants = pd.read_csv(\"restaurants_final.csv\", index_col=False)\n",
    "#restaurants = restaurants[['식당명', '방송']]\n",
    "#restaurants = restaurants[41:]\n",
    "#restaurants.sort_values(by='식당명', inplace=True)\n",
    "\n",
    "## 모든 식당에 대해 크롤링 수행\n",
    "#for _, row in restaurants.iterrows():\n",
    "#    crawl_youtube_comments(driver, row['방송'], row['식당명'])\n",
    "\n",
    "## 드라이버 종료\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cb0643",
   "metadata": {},
   "source": [
    "# URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06838c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 식당 csv 파일 불러오기\n",
    "restaurants = pd.read_csv(\"restaurants_final.csv\", index_col=False)\n",
    "restaurants = restaurants[['식당명', '방송']]\n",
    "restaurants = restaurants[41:]\n",
    "restaurants.sort_values(by='식당명', inplace=True)\n",
    "restaurants['식당명'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromeDriver 설정\n",
    "options = Options()\n",
    "# options.add_argument('--headless')  # GUI 없이 실행 (필요 시 활성화)\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# WebDriver 생성\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# 유튜브 댓글 크롤링 함수\n",
    "def crawl_youtube_comments(driver, url):\n",
    "    results = []\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        # 동영상 제목 로드 대기\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '#title > h1 > yt-formatted-string'))\n",
    "        )\n",
    "        video_title = driver.find_element(By.CSS_SELECTOR, '#title > h1 > yt-formatted-string').text\n",
    "        print(f\"Processing Title: {video_title}\")\n",
    "\n",
    "        # 댓글 로드: 페이지 스크롤\n",
    "        body = driver.find_element(By.TAG_NAME, 'body')\n",
    "        for _ in range(15):  # 스크롤 횟수 조정 가능\n",
    "            body.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(1)\n",
    "\n",
    "        # 댓글과 사용자 정보 수집\n",
    "        comments = driver.find_elements(By.CSS_SELECTOR, '#content-text')\n",
    "        users = driver.find_elements(By.CSS_SELECTOR, 'a#author-text')\n",
    "        for comment, user in zip(comments, users):\n",
    "            results.append({\n",
    "                \"URL\": url,\n",
    "                \"Title\": video_title,\n",
    "                \"User\": user.text.strip(),\n",
    "                \"Comment\": comment.text.strip(),\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video at {url}: {e}\")\n",
    "    return results\n",
    "\n",
    "# URL 리스트\n",
    "urls = [\n",
    "    'https://www.youtube.com/watch?v=KcchqqFvFVo&pp=ygUc7Y-s67Cp7KO86r6466-4IOqzqOuqqeyLneuLuQ%3D%3D'\n",
    "    'https://www.youtube.com/watch?v=rZRKzRc_UEo&pp=ygUc7Y-s67Cp7KO86r6466-4IOqzqOuqqeyLneuLuQ%3D%3D',\n",
    "    'https://www.youtube.com/watch?v=7-Is-FkhPgo&pp=ygUc7Y-s67Cp7KO86r6466-4IOqzqOuqqeyLneuLuQ%3D%3D',\n",
    "    'https://www.youtube.com/watch?v=VANU9Funja8&pp=ygUc7Y-s67Cp7KO86r6466-4IOqzqOuqqeyLneuLuQ%3D%3D',\n",
    "    'https://www.youtube.com/watch?v=OWnurZ2-mT0&pp=ygUc7Y-s67Cp7KO86r6466-4IOqzqOuqqeyLneuLuQ%3D%3D',\n",
    "]\n",
    "\n",
    "# 모든 URL의 결과를 저장할 리스트\n",
    "all_results = []\n",
    "\n",
    "# 각 URL에 대해 크롤링 수행\n",
    "for url in urls:\n",
    "    results = crawl_youtube_comments(driver, url)\n",
    "    all_results.extend(results)\n",
    "\n",
    "# 모든 데이터를 하나의 CSV 파일로 저장\n",
    "if all_results:\n",
    "    output_file = \"youtube_comments_포방주꾸미.csv\"\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Saved all comments to {output_file}\")\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2096df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "directory = os.getcwd()\n",
    "\n",
    "# List to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for file in os.listdir(directory):\n",
    "    # Check if the file matches the pattern 'youtubecomments_{식당}.csv'\n",
    "    if file.startswith(\"youtubecomments_\") and file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            # Read the CSV file and append to the list\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "output_file = os.path.join(directory, \"combined_youtubecomments.csv\")\n",
    "combined_df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Combined CSV saved as {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
